size 가 안 맞다? 
	1. data 잘못 봄!
	2. 세트가 안 맞다? -> 전처리 필요!
	
결정트리
> 분류와 회귀에서 쓰인다

선형모델: 회귀를 많이 쓰는 경향성

결정트리는 분류나 회귀 보다는 [장점]중요특성(질문을 통한 답변 형식) 파악 용도로 많이 쓴다.*
-> 복잡도 제어가 가장 중요: depth 가 깊어지면 overfitting

[단점]데이터의 민감도가 너무 높다. -> 그래서 랜덤 포레스트를 쓴다.

오버피팅 대안은 매개변수 조정이다.

train_test_split: 문제를 잘 섞는 용도
> 문제 균등 분류가 힘들기에
> 내가 하려면 싹다 함수로 만들어야
> 표본검정을 통과하는 알고리즘이어야

max_depth 조정: 하이퍼 파라미터

113 페이지와 같은 수형도 그릴 줄 알아야 한다.

랜덤 포레스트
> 중요특성 파악
> [단점] 계산량 폭증
> 전처리 안해도 된다.
> 데이터 민감 해결
> 단일 앙상블 모델

결정트리로 중요특성 파악 후 랜덤 포레스트를 사용한다.

<라이브러리>

데이터 | Pandas
x, y | 데이터나눔
fit() | 함수
score | 평가

---

결정트리 + 랜덤포레스트 [현업] => XgBoost [경진대회]

SVM 회귀모델은 선형 모델이 강세, SVM은 데이터가 얼마 없을 때 쓰인다.
-> SVM 은 분류와 회귀에 다 쓴다.

---

데이터 민감도를 고려허면 결정트리 X
주요특성 파악하는데 결정트리만한 것이 없다.

선형모델 -> 일단 랜덤 포레스트 먼저 돌려 -> 결과 0.64 -> 판다스 로 정리 -> 중요 특성 뽑아 전터리 -> 0.74
-> 두세개 더 확인 -> 0.74 유지하면 그건 빼버려! -> 

0.67 -> SVM -> 0.8 -> 게임 끝!

실습은 내일!

